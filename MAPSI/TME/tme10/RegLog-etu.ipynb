{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME 10 : méthodes discriminantes\n",
    "\n",
    "Le but de ce TME est de comparer les approches en modélisation maximum de vraisemblance et maximum a posteriori au niveau de la modélisation même du problème dans le cas de la classification. \n",
    "\n",
    "Nous notons  les observations $\\mathbf x_i \\in \\mathbb R^d$ et les étiquettes binaires associées $y_{i} \\in \\mathcal Y = \\{0, 1\\}$.\n",
    "Nous faisons l'hypothèse que les couples $(\\mathbf x_i, y_{i})$ sont tirés de manière i.i.d. et suivent une loi inconnue $P(X,Y)$. \n",
    "\n",
    "***Résumé du max de vraisemblance:***<BR>\n",
    "1. Choix d'une modélisation $\\Theta$ pour les $\\mathbf x_i$ (par exemple une gaussienne multivariée ou une modélisation dimension par dimension selon une loi choisie en accord avec les experts du domaine).\n",
    "1. Formalisation de la vraisemblance pour un échantillon:\n",
    "$p(\\mathbf x_i | \\Theta)$\n",
    "1. Pour chaque classe $y$ (0 ou 1 dans le cas présent), optimisation de \n",
    "    $$\\Theta_y^\\star = \\arg \\max_{\\Theta} \\prod_{i \\in y} p(\\mathbf x_i | \\Theta)$$\n",
    "1. Critère de décision pour un nouvel échantillon $\\mathbf x_n$:\n",
    "    $$\\hat y_n = \\arg \\max_c p(\\mathbf x_n | \\Theta_y) $$\n",
    "\n",
    "La méthode est simple et efficace mais ne compare jamais les échantillons des différentes classes pour prendre une décision.\n",
    "\n",
    "***Idée des approches discriminantes:***<BR>\n",
    "1. Choix d'un modèle pour $p(y_i | \\mathbf x_i)$. Le modèle le plus connu est la régression logistique qui, comme le nom ne l'indique pas est un modèle de classification. C'est ce modèle que nous allons étudier:\n",
    "    $$p(y_i=1 | \\mathbf x_i) = \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))},\\qquad \\mbox{Paramètres : } \\mathbf w, b $$\n",
    "1. Dans le cas à deux classes uniquement; après avoir remarqué que nous avons choisi un codage des classes de type Bernoulli... Utilisation de l'astuce de Bernoulli pour calculer la vraisemblance d'un échantillon:\n",
    "$$ p(y_i | \\mathbf x_i) = \\left( \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}\\right)^{y_i} \\left(1- \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}\\right)^{1-y_i} $$\n",
    "1. Max de vraisemblance sur ***sur l'ensemble des données***:\n",
    "    $$\\mathbf w^\\star, b^\\star = \\arg \\max_{\\mathbf w, b} \\prod_{i} p(\\mathbf x_i, y_i | \\mathbf w, b) = \\arg \\max_{\\mathbf w, b} \\prod_{i} p( y_i|\\mathbf x_i, \\mathbf w, b) p(\\mathbf x_i| \\mathbf w, b)$$\n",
    "En faisant l'hypothèse que les $\\mathbf x_i$ sont équiprobables (pas de poids sur les observations):\n",
    "$$\\mathbf w^\\star, b^\\star = \\arg \\max_{\\mathbf w, b} \\prod_{i} p( y_i|\\mathbf x_i, \\mathbf w, b)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des librairies et des données USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    f=open(filename,'r')\n",
    "    s = f.readline() # virer la premiere ligne\n",
    "    X = np.array([[float(d) for d in lig.split()] for lig in f if len(lig)>10])\n",
    "    Y = X[:,0] # premiere colonne\n",
    "    X = X[:,1:]\n",
    "    f.close()\n",
    "    return X,Y\n",
    "\n",
    "X,Y = load('data/usps_train.txt')\n",
    "Xt,Yt = load('data/usps_test.txt')\n",
    "\n",
    "# affichage d'un échantillon\n",
    "plt.figure()\n",
    "index = 0\n",
    "plt.imshow(X[index].reshape(16,16), interpolation=None)\n",
    "plt.title('Affichage d\\'un échantillon de la classe: '+str(Y[index]))\n",
    "\n",
    "# étude très rapide des données:\n",
    "plt.figure()\n",
    "plt.hist(Y, 10) # histogramme de répartition des 10 classes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1: retour sur le max de vraisemblance\n",
    "\n",
    "Nous retravaillons rapidement le max de vraisemblance pour obtenir un baseline. Nous allons travailler en bayesien naif sur des images binarisées:\n",
    "$$ x_{ij} \\in \\{0,1\\}, \\qquad p(x_i | \\Theta) = \\prod_j p(x_{ij} | \\Theta_j)$$\n",
    "\n",
    "Le code est fourni, il suffit de l'exécuter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage d'un modèle de Bernoulli naif par classe\n",
    "def learnBernoulli (X,Y):\n",
    "    theta = [(X[Y==y].mean(0)) for y in np.unique(Y)]\n",
    "    return np.array(theta)\n",
    "\n",
    "# evaluation de la vraisemblance d'une base d'échantillon\n",
    "# retourne une matrice avec les vraisemblances des échantillons pour toutes les classes\n",
    "def logpobsBernoulli(X, theta):\n",
    "    seuil = 1e-4\n",
    "    theta = np.maximum(np.minimum(1-seuil, theta),seuil)\n",
    "    logp = [[ (x*np.log(mod)+(1-x)*np.log(1-mod)).sum() for x in X] for mod in theta ]\n",
    "    return np.array(logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binariser X (sinon la modélisation Bernoulli ne tient plus)\n",
    "Xb = np.where(X >0, 1., 0.)\n",
    "Xbt = np.where(Xt >0, 1., 0.)\n",
    "\n",
    "\n",
    "## Max de Vraisemblance\n",
    "theta = learnBernoulli ( Xb,Y )\n",
    "## Evaluation de la vraisemblance des échantillons\n",
    "logp  = logpobsBernoulli(Xb, theta)\n",
    "logpT = logpobsBernoulli(Xbt, theta)\n",
    "\n",
    "# calcul des y de prédiction à partir de la matrice des vraisemblances\n",
    "ypred_b  = logp.argmax(0)\n",
    "ypredT_b = logpT.argmax(0)\n",
    "\n",
    "print(\"Bernoulli : Taux bonne classification en apprentissage : \",np.where(ypred_b != Y, 0.,1.).mean())\n",
    "print(\"Bernoulli : Taux bonne classification en test : \",np.where(ypredT_b != Yt, 0.,1.).mean())\n",
    "\n",
    "# resultats qualitatifs: affichage des poids du modèle de la classe 0\n",
    "plt.figure()\n",
    "plt.imshow(theta[0].reshape(16,16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2: prise en compte des informations a priori et passage au MAP\n",
    "\n",
    "La seule information dont nous disposons est la répartition des classes (cf histogramme).\n",
    "1. Calcul des probabilités a priori des classes \n",
    "1. Evaluation des performances avec prise en compte de ces informations a priori\n",
    "1. Afficher les images des chiffres qui changent de classe avec les prédictions avant/après\n",
    "\n",
    "Cet exercice correspondant principalement à des compétences de séances précédentes, le code est fourni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTION\n",
    "pAPriori = np.array([np.where(Y==i, 1, 0).sum() for i in np.unique(Y)]).reshape(10,1) / len(Y)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(pAPriori.T, interpolation=None)\n",
    "plt.title('Distribution des classes')\n",
    "\n",
    "# pas de modification sur les paramètres optimaux\n",
    "ypred  = (logp + np.log(pAPriori)).argmax(0) # utilise le dispatch numpy\n",
    "ypredT = (logpT+ np.log(pAPriori)).argmax(0)\n",
    "\n",
    "print (\"Bernoulli : Taux bonne classification MAP en apprentissage : \",np.where(ypred != Y, 0.,1.).mean())\n",
    "print (\"Bernoulli : Taux bonne classification MAP en test : \",np.where(ypredT != Yt, 0.,1.).mean())\n",
    "\n",
    "# recherche d'un point ayant changé de classe avec le MAP:\n",
    "index = np.where(ypred != ypred_b)[0]\n",
    "plt.figure()\n",
    "plt.subplots(1,len(index))\n",
    "for num,i in enumerate(index):\n",
    "    plt.subplot(1,len(index),num+1) # subplot commence à 1 (héritage matlab)\n",
    "    plt.imshow(Xb[i].reshape(16,16))\n",
    "    plt.title(\"y = \"+str(int(Y[i])) + \",\"+str(ypred[i])+\",\"+str(ypred_b[i]) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3: codage de la régression logistique\n",
    "\n",
    "***Rappel: régression logistique = système de classification***\n",
    "\n",
    "$$ p(y_i | \\mathbf x_i) = \\left( \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}\\right)^{y_i} \\left(1- \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}\\right)^{1-y_i} $$\n",
    "\n",
    "\n",
    "Soit en agrégeant sur la base de données et notant: $exp = \\exp( -(  \\mathbf x_i  \\mathbf w + b))$\n",
    "$$\\mathcal L_{log} = \\sum_i  y_i \\log(\\frac{1}{1+exp}) + (1-y_i) \\log(1-\\frac{1}{1+exp})$$ \n",
    "$$\\mathcal L_{\\log}=\\sum_{i=1}^N \\log(1+exp) ( -y_i -1 + y_i) + \\log(exp)(1-y_i)$$\n",
    "\n",
    "Soit:\n",
    "$$ \\frac{\\partial  }{\\partial w_j} L_{\\log} =\\sum_{i=1}^N x_{ij}( y_i-\\frac{1}{1+exp}) \\in \\mathbb R$$\n",
    "On remarque qu'il est possible de passer à une écriture vectorielle:\n",
    "$$ \\nabla_{\\mathbf w} L_{\\log} =X^T ( Y-\\frac{1}{1+\\exp( -(  \\mathbf X  \\mathbf w + b))}) \\in \\mathbb R^d$$\n",
    "$$ \\frac{\\partial  }{\\partial b} L_{\\log} =\\sum_{i=1}^N ( y_i-\\frac{1}{1+exp}) \\in \\mathbb R$$\n",
    "\n",
    "Note: il est possible de manière **facultative**, comme dans le TME de la semaine dernière, de construire:\n",
    "$$Xe = \\left[\\begin{array}{cc}\n",
    "                \\mathbf x_0 & 1\\\\\n",
    "                \\vdots & \\vdots\\\\\n",
    "                \\mathbf x_N & 1\n",
    "                \\end{array}\n",
    "                \\right] $$\n",
    "On supprime alors les $b$ pour obtenir:\n",
    "$$ \\nabla_{\\mathbf w_e} L_{\\log} =X_e^T ( Y-\\frac{1}{1+\\exp( -(  \\mathbf X_e  \\mathbf w_e))}) \\in \\mathbb R^{d+1}$$\n",
    "\n",
    "### Liste des questions\n",
    "1. Coder la descente de gradient classique (batch) entre deux classes <BR>\n",
    "    Attention, il s'agit d'une montée de gradient pour maximiser la vraisemblance <BR>\n",
    "    Proposition de critère d'arrêt: $\\max_j(|w_{new,j} - w_{old,j}| ) < 10^{-3}$\n",
    "1. Evaluer les performances sur la distinction entre les 2 et les 3\n",
    "1. Passer au multi-classe avec le paradigme un-contre-tous\n",
    "1. [OPT, à faire à la fin] passer à un algorithme de gradient stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. montée de gradient\n",
    "def rl_gradient_batch(X,Y, epsilon = 1e-3, niter_max=1000):\n",
    "    N,d = X.shape\n",
    "    # TODO\n",
    "    return w,b # ou seulement w si vous avez ajouté les 1 dans X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. cas sur les classes 2 et 3 & passage à un codage 0/1 pour Y\n",
    "cl1 = 2\n",
    "cl2 = 3\n",
    "X_23 = X[(Y==cl1)|(Y==cl2),:]\n",
    "Y_23 = np.where(Y[(Y==cl1)|(Y==cl2)] == cl1, 1., 0.)\n",
    "Xt_23 = Xt[(Yt==cl1)|(Yt==cl2),:]\n",
    "Yt_23 = np.where(Yt[(Yt==cl1)|(Yt==cl2)] == cl1, 1., 0.)\n",
    "print(\"Taille des données :\",X_23.shape,Y_23.shape)\n",
    "\n",
    "# application de la montée de gradient & evaluation des performances\n",
    "# attention à afficher les Ypred et les Y_23 pour vérifier qu'ils sont comparables\n",
    "# vous pouvez utiliser np.round\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sortie attendue\n",
    "```\n",
    "Taille des données : (1389, 256) (1389,)\n",
    "convergence atteinte en  330  itérations # si vous avez fait un print dans le critère d'arret\n",
    "[0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.] \n",
    " [0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
    "App :  0.9992800575953924\n",
    "Test :  0.9615384615384616\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(w.reshape(16,16))\n",
    "plt.savefig(\"w23.png\")\n",
    "# montrer les paramètres des modèles génératifs des classes 2 et 3 pour comparer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passage au multiclasse\n",
    "\n",
    "Nous allons utiliser le paradigme *un-contre-tous* mais nous allons le coder proprement dans une fonction.\n",
    "Dans la fonction ```rl_multi(X,Y, epsilon = 1e-3, niter_max=1000)``` effectuer les opérations suivantes:\n",
    "\n",
    "1. Extraire toutes les classes de Y\n",
    "1. Pour chaque classe\n",
    "11. Construire Ycl telle que:\n",
    "$$Y_{cl} = \\left\\{ \n",
    "\\begin{array}{cl}\n",
    "1 & \\mbox{ si } Y == cl     \\\\\n",
    "0 & \\mbox{ sinon (pour toutes les autres classes) }\n",
    "\\end{array}\n",
    "\\right.$$\n",
    "11. Lancer un apprentissage\n",
    "1. Empiler tous les $\\mathbf w$ & $b$ comme suit:\n",
    "\n",
    "$$W = \\left[\\begin{array}{cccc}\n",
    "                \\\\\n",
    "                \\mathbf w_{cl=0} & \\mathbf w_{cl=1} & \\ldots & \\mathbf w_{cl=9}\n",
    "                \\\\ \\\\\n",
    "                \\end{array}\n",
    "                \\right] $$\n",
    "$$\\mathbf b = \\left[\\begin{array}{cccc}\n",
    "                \\mathbf b_{cl=0} & \\mathbf b_{cl=1} & \\ldots & \\mathbf b_{cl=9}\n",
    "                \\end{array}\n",
    "                \\right] $$\n",
    "                \n",
    "On peut alors montrer que:\n",
    "$$ \\frac{1}{1+\\exp( - \\mathbf X W - \\mathbf b)}  = \\left[\\begin{array}{cccc}\n",
    "                p(Y = 1 | X = \\mathbf x_1) & p(Y = 2 | X = \\mathbf x_1) & \\ldots & p(Y = 9 | X = \\mathbf x_1)\n",
    "                \\\\ \n",
    "                \\vdots & &\\ddots & \\vdots\\\\\n",
    "p(Y = 1 | X = \\mathbf x_N) & p(Y = 2 | X = \\mathbf x_N) & \\ldots & p(Y = 9 | X = \\mathbf x_N)\n",
    "\\\\\n",
    "                \\end{array}\n",
    "                \\right] \\in \\mathbb R^{N\\times C}$$\n",
    "               Avec $N$ points et $C$ classes\n",
    "1. Utiliser un ```argmax``` pour extraire le numéro de classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_multi(X,Y, epsilon = 1e-3, niter_max=1000):\n",
    "    N,d = X.shape\n",
    "    classes = np.unique(Y)\n",
    "    # Initialiser les poids & lancer un modèle par classe\n",
    "    # dans la boucle for, vous pouvez utiliser : Y_tmp = np.where(Y == c, 1., 0.)\n",
    "    # TODO\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duree execution = 30 secondes\n",
    "# n'hésitez pas à mettre un niter_max à 10 durant la phase de debug pour gagner du temps !\n",
    "W,B = rl_multi(X,Y)\n",
    "\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf:\n",
    "Y_pred  = np.argmax(1/(1+np.exp(-X@W - B)),1)\n",
    "Yt_pred = np.argmax(1/(1+np.exp(-Xt@W -B)),1)\n",
    "# print(Yt[:20],\"\\n\",Yt_pred[:20])\n",
    "    \n",
    "pc_good   = np.where(Y_pred == Y , 1., 0.).mean()\n",
    "pc_good_t = np.where(Yt_pred==Yt , 1., 0.).mean()\n",
    "\n",
    "print(\"App : \",pc_good)\n",
    "print(\"Test : \",pc_good_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances attendues:\n",
    "```\n",
    "App :  0.8824578247154026\n",
    "Test :  0.8166417538614849\n",
    "```\n",
    "Pour l'instant, on ne voit pas encore l'intérêt... Mais ça va venir!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4: Analyse de l'évolution de la vraisemblance \n",
    "\n",
    "Afin de vérifier le bon fonctionnement de l'algorithme, nous proposons de calculer la vraisemblance au cours des itérations (par exemple, toutes les 10 itérations) et de retourner le résultat pour voir comment se déroule l'apprentissage et pouvoir éventuellement ajuster la valeur de $\\epsilon$.\n",
    "\n",
    "En repartant de:\n",
    "$$\\mathcal L_{log} = \\sum_i  y_i \\log(\\frac{1}{1+exp}) + (1-y_i) \\log(1-\\frac{1}{1+exp})$$ \n",
    "Avec : $exp = \\exp( -(  \\mathbf x_i  \\mathbf w + b))$\n",
    "\n",
    "Modifier la fonction de calcul de la vraisemblance pour retourner l'évolution de la vraisemblance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_gradient_batch_L(X,Y, epsilon = 1e-3, niter_max=1000):\n",
    "    N,d = X.shape\n",
    "    L = [] # init vraisemblance\n",
    "    # meme code que précédemment\n",
    "    # même si c'est peu recommandé en GL... Faites un copier-coller pour gagner du temps\n",
    "    # TODO\n",
    "    return w,b,np.array(L)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cas sur les classes 2 et 3 & passage à un codage 0/1 pour Y\n",
    "cl1 = 2\n",
    "cl2 = 3\n",
    "X_23 = X[(Y==cl1)|(Y==cl2),:]\n",
    "Y_23 = np.where(Y[(Y==cl1)|(Y==cl2)] == cl1, 1., 0.)\n",
    "Xt_23 = Xt[(Yt==cl1)|(Yt==cl2),:]\n",
    "Yt_23 = np.where(Yt[(Yt==cl1)|(Yt==cl2)] == cl1, 1., 0.)\n",
    "#print(\"Taille des données :\",X_23.shape,Y_23.shape)\n",
    "\n",
    "w,b,L = rl_gradient_batch_L(X_23,Y_23, epsilon = 1e-3)\n",
    "#print(L)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5: Analyse qualitative des solutions\n",
    "\n",
    "Quels sont les pixels qui jouent un role dans la décision?\n",
    "\n",
    "1. Pour une classe de données, je peux déjà afficher l'ampleur des poids $\\mathbf w$ associés à chaque classe. Cela indique si les pixels sont pondérés positivement ou négativement.\n",
    "1. Pour une image donnée, je sais que la décision est de la forme:\n",
    "$$p(y_i=1 | \\mathbf x_i) = \\frac{1}{1 + \\exp( -(  \\mathbf x_i  \\mathbf w + b))}$$\n",
    "Ainsi, la décision est formée d'une addition de $x_{ij}\\cdot w_j$: les plus fortes composante en valeur absolue sont celles qui participent le plus à la décision. <BR>\n",
    "Cette approche est particulièrement intéressante pour analyser les erreurs de classification.\n",
    "Afficher l'image d'un chiffre mal classé et une carte de chaleur indiquant quelles parties de l'image influencent le plus la décision: pour la classe prédite d'une part et pour la classe réelle d'autre part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage des poids des paramètres des 10 classes (PAS DE CODE A AJOUTER)\n",
    "# prérequis: que les w soit en colonnes dans la matrice W\n",
    "plt.figure()\n",
    "plt.subplots(2, 5)\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5,i+1)\n",
    "    plt.imshow(W[:,i].reshape(16,16), cmap=\"gray\")\n",
    "    plt.title(\"modèle \"+str(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver un échantillon mal classé (PAS DE CODE A AJOUTER):\n",
    "\n",
    "index = np.where(Y != Y_pred)[0][0] # parmi les points d'apprentissage\n",
    "print(index)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplots(1,3)\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(X[index].reshape(16,16),cmap=\"gray\")\n",
    "plt.title(\"Chiffre\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow((X[index]*W[:,int(Y[index])]).reshape(16,16),cmap=\"plasma\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Heatmap cl \"+str(int(Y[index])))\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow((X[index]*W[:,int(Y_pred[index])]).reshape(16,16),cmap=\"plasma\")\n",
    "plt.title(\"Heatmap cl \"+str(int(Y_pred[index])))\n",
    "plt.colorbar()\n",
    "plt.savefig(\"malclasse.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5-2: limite de la représentation des chiffres\n",
    "\n",
    "L'expérience précédente met en lumière un phénomène évident: seuls les pixels non nuls jouent un role dans la classification.\n",
    "C'est très pénalisant, le fait qu'un pixel soit éteint ne peut influencer la décision que par son inaction... Mais pas forcer le système à aller dans une autre classe.\n",
    "\n",
    "Ce problème est aisément contournable: il suffit de travailler sur $X-1$ (les valeurs de pixels étant entre $0$ et $2$). Les $-1$ qui apparaissent vont alors jouer un role dans la décision.\n",
    "\n",
    "1. Ré-utiliser (sans modification) ```rl_multi``` sur $X-1$\n",
    "1. Calculer les performances en pensant bien à faire l'inférence sur $Xt-1$\n",
    "1. Afficher les contributions des pixels dans cette nouvelle configuration pour une image mal classée\n",
    "\n",
    "Note: avec la régression logistique, les classes $Y$ doivent être dans $\\mathcal Y=\\{0,1\\}$... Mais il n'y a pas de contrainte sur les $X$. Ajouter des descripteurs négatifs n'est pas un problème.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il n'y a pas de méthode à redéfinir...\n",
    "# juste apprendre un nouveau modèle sur des données modifiées... Et ne pas faire d'erreur en inférence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sortie attendue:\n",
    "```\n",
    "App :  0.9663969277191058\n",
    "Test :  0.8938714499252616\n",
    "```\n",
    "On commence à voir l'intérêt de la régression logistique !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver un échantillon mal classé (PAS DE CODE A AJOUTER):\n",
    "\n",
    "index = np.where(Y != Y_pred)[0][0] # parmi les points d'apprentissage\n",
    "print(index)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplots(1,3)\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(X[index].reshape(16,16),cmap=\"gray\")\n",
    "plt.title(\"Chiffre\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(((X[index]-1)*Wm[:,int(Y[index])]).reshape(16,16),cmap=\"plasma\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Heatmap cl \"+str(int(Y[index])))\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(((X[index]-1)*Wm[:,int(Y_pred[index])]).reshape(16,16),cmap=\"plasma\")\n",
    "plt.title(\"Heatmap cl \"+str(int(Y_pred[index])))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6: Régularisation, performance & interprétation\n",
    "\n",
    "Dans ce problème en assez grande dimension (256), nous voyons un peu de sur-apprentissage: les performances sont meilleures en apprentissage qu'en test.\n",
    "\n",
    "On fait souvent l'hypothèse que ce phénomène est lié à un estimateur trop complexe. Afin de simplifier la fonction de coût, on proposer de régulariser le problème d'apprentissage qui devient:\n",
    "\n",
    "$$\\arg\\max_\\theta  \\mathcal L - \\lambda \\Omega(\\theta), \\qquad \\mbox{avec: } \\Omega(\\theta) = \\left\\{\\begin{array}{cl}\n",
    "\\sum_j \\theta_j^2 & \\mbox{ régularisation } L_2 \\\\\n",
    "\\sum_j |\\theta_j| & \\mbox{ régularisation } L_1 \\\\\n",
    "\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "$\\lambda$ doit être choisi soigneusement sous peine d'aboutir à une solution dégénée (ou non modifiée). La régularisation $L_2$ est plus stable est facile à exploiter, la régularisation $L_1$ est plus complexe et moins stable mais elle permet d'annuler complètement les poids attribués à certains pixels. En effet, dans l'implémentation, nous allons traiter la fonction $\\Omega$ à part de la vraisemblance:\n",
    "Toutes les itérations, nous allons mettre à jour:\n",
    "\n",
    "$$\\mathbf w \\leftarrow \\mathbf w - \\lambda \\left\\{\\begin{array}{cl}\n",
    "\\nabla_{\\mathbf w,b} \\Omega(\\mathbf w,b) = 2\\mathbf w, 2b  & \\mbox{ régularisation } L_2 \\\\\n",
    "\\nabla_{\\mathbf w,b} \\Omega(\\mathbf w,b) = sign(\\mathbf w),sign(b) & \\mbox{ régularisation } L_1 \\\\\n",
    "\\end{array}\n",
    "\\right. $$\n",
    "\n",
    "En interprétant la formule ci-dessus, on se rend compte que ça ramène systématiquement les poids du modèle vers 0: l'idée est donc bien de simplifier le modèle... Seuls les dimensions vraiment intéressantes seront pondérées.\n",
    "\n",
    "**Note:** Par défaut, il n'est pas évident d'améliorer les performances avec la régularisation sur ce problème... C'est néanmoins une procédure très efficace sur la plupart des jeux de données.\n",
    "\n",
    "**Note2:** Les expériences étant un peu chères en temps de calcul, pensez à réduire niter_max pendant le debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_gradient_batch_reg(X,Y, epsilon = 1e-3, niter_max=1000, lam=1e-5):\n",
    "    N,d = X.shape\n",
    "    # TODO\n",
    "    return w,b\n",
    "\n",
    "# Soit vous passez des fonctions en arguments, soit il faut redéfinir une nouvelle version de rl_multi\n",
    "# dans le cadre du TP, on prend la seconde option: plus simple mais plus moche\n",
    "def rl_multi_reg(X,Y, epsilon = 1e-3, niter_max=1000, lam=1e-5):\n",
    "    #TODO\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation des performances\n",
    "# TODO\n",
    "\n",
    "pc_good   = np.where(Y_pred == Y , 1., 0.).mean()\n",
    "pc_good_t = np.where(Yt_pred==Yt , 1., 0.).mean()\n",
    "\n",
    "print(\"App : \",pc_good)\n",
    "print(\"Test : \",pc_good_t)"
   ]
  },
  {
   "attachments": {
    "CurseDim.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6: Malédiction de la dimensionnalité\n",
    "\n",
    "Nous vous proposons ici de modifier les données pour ajouter des colonnes de bruit. Montrer que la performances se réduit lorsque l'on augmente le nombre de dimensions fantomes.\n",
    "\n",
    "- la fonction d'ajout des données fantomes est fournie\n",
    "- faites la boucle avec des ajouts de $[0,100,150,200,250]$ colonnes et tracer l'évolution des performances en apprentissage et en test.\n",
    "    - Attention: il faut donc modifier $X$ et $Xt$ avec le même nombre de colonne fantome\n",
    "    \n",
    "**Note:** les expériences sont couteuses, encore une fois, limitez niter_max ou faites les calculs sur un serveur distant (3 minutes en limitant à 300 itérations)... <BR>\n",
    "Attention, le fait de limiter les itérations est une forme de régularisation (appelée *early stopping*): s'il n'y a pas assez d'itération, on ne voit pas les effets pervers de la dimensionnalité des données!\n",
    "\n",
    "**Note 2:** Evidemment, c'est dans ce cas de figure -qui correspond à beaucoup d'applications réelles- que la régularisation va aider.\n",
    "\n",
    "Avec 300 itérations, vous obtenez:\n",
    "![CurseDim.png](attachment:CurseDim.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute du bruit (et on enlève 1) \n",
    "# ATTENTION : ne pas enlever une seconde fois 1 ensuite !\n",
    "def ajout_colonne_randn(X,d, sig = 1.):\n",
    "    return np.hstack((X-1, np.random.randn(len(X),d)*sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnoise    = np.array([0,100,150,200,250])\n",
    "perf_app  = np.zeros(len(dnoise))\n",
    "perf_test = np.zeros(len(dnoise))\n",
    "\n",
    "for i,d in enumerate(dnoise):\n",
    "    #TODO\n",
    "    perf_app[i]   = np.where(Y_pred == Y , 1., 0.).mean()\n",
    "    perf_test[i]  = np.where(Yt_pred==Yt , 1., 0.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(dnoise,perf_app, 'r')\n",
    "plt.plot(dnoise,perf_test, 'b')\n",
    "plt.legend(['App','Test'])\n",
    "plt.grid()\n",
    "plt.savefig('CurseDim.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 7: et par rapport aux méthodes discriminantes à base de fonctions de cout?\n",
    "\n",
    "Tester l'algorithme du perceptron vu en cours, avec l'astuce du un-contre-tous pour le passage au multi-classes.\n",
    "Attention, pour le perceptron, le codage des deux classes est en $\\{-1, 1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

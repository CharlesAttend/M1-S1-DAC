\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage[french]{babel}

\usepackage[default,scale=0.95]{opensans}
\usepackage[T1]{fontenc}
\usepackage{amssymb} %math
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{systeme}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={MAPSI},
    % pdfpagemode=FullScreen,
    }
\urlstyle{same} %\href{url}{Text}

\theoremstyle{plain}% default
\newtheorem{thm}{Théorème}[section]
\newtheorem{lem}[thm]{Lemme}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollaire}
%\newtheorem*{KL}{Klein’s Lemma}

\theoremstyle{definition}
\newtheorem{defn}{Définition}[section]
\newtheorem{exmp}{Exemple}[section]
% \newtheorem{xca}[exmp]{Exercise}

\theoremstyle{remark}
\newtheorem*{rem}{Remarque}
\newtheorem*{note}{Note}
%\newtheorem{case}{Case}



\title{Cours: MAPSI}
\author{Charles Vin}
\date{2022}

\begin{document}
\maketitle
\underline{Nouveau cours du 13/09} \\
\section{Introduction}

\begin{itemize}
    \item Exam final : 50\%
    \item Partiel : 35\%
    \item Participation : 15\%
    \begin{itemize}
        \item travail dans la séance
        \item TME soumis en fin de séance omg 
    \end{itemize}
\end{itemize}

Deux grand type de modèle : \begin{itemize}
    \item Modèle paramétrique : connaissance sur la distribution stat des données. Puis on estime les paramètres de la loi.
    \item Modèle non paramétrique : l'inverse, on ne connait pas la loi. exemple : regression logistique
\end{itemize}

Echantillons : \begin{itemize}
    \item population
    \item ect 
\end{itemize}

\begin{defn}[]
    Vocabulaire :   
    \begin{itemize}
        \item Voir diapo 9/51
    \end{itemize}
\end{defn}

\begin{defn}[Mesure de proba]
    Une fonction qui associe chaque événement à une valeur entre 0 et 1.
    Voir diapo 15, definition importante.
\end{defn}

\begin{defn}[]
    \[
        P(A \cup B) = P(A) + P(B) - P(A \cap B)
    .\]
    Densité de proba 
    \[
        \text{Retrouver la définition}
    .\]
    
    Fonction de répartition
    \[
        F(x) = P(X<x) = \int_{-\infty }^{x}f(x)dx
    .\]
    Espérance : \begin{align*}
        E(X) &= \sum_{}^{}x_k*p_k \\
        E(X) &= \int_{}^{}X p(x) dx \\ 
        E(aX+b) = aE(X) + b \\
        E(X + Y) = E(X)+E(Y)
    \end{align*}

    Le Mode \begin{align*}
        p(Mo) = \max _k p(x_k)
        p(Mo) = \max _x p(x)
    \end{align*}

    Variance : \begin{align*}
        \sigma ^2 = \sum_{}^{}(x_k - E(X))^2 \\
        \sigma ^2 = \int_{}^{}(x-E(X))^2 p(x)dx \\
        V(aX+b) = a^2V(X) \\
        V(X) = E(X^2) - E(X)
    \end{align*}

    Médiane et quantile \begin{align*}
        \text{idk diapo}
    \end{align*}
\end{defn}

\begin{defn}[Loi marginale]
    La marginalisation consiste à projeter une loi jointe sur l'une des variables aléatoires. Par exemple extraire $ P(A) $ à partir de $ P(A,B) $. 
    \[
        P(A) = \sum_{i}^{}P(A, B = p b_i)
    .\]
    C'est la somme de la ligne ou de la colonne du tableau.
\end{defn}

\begin{defn}[]
    Probabilités conditionnelles
    \begin{align*}
        &P(A|B) = \frac{P(A \cup B)}{P(B)} \\ 
        \Leftrightarrow& P(A \cup B) = P(A|B)P(B)
    \end{align*}
    \begin{prop}[]
        \begin{itemize}
            \item Réversibilité : $ P(A,B) = P(A|B) $
            \item Théorème de Bayes : 
            \[
                P(A|B) = \frac{P(B|A)P(A)}{P(B)}
            .\]
            \item Intégration des probabilités totale
            \item DIAPO 39
        \end{itemize}
    \end{prop}    
    
\end{defn}

\begin{defn}[Indépendance probabiliste]
    Deux événements A et B sont indépendants si 
    \[
        P(A,B) = P(A) * P(B)
    .\]
    Corollaire : $ P(A|B) = P(A) $ 
\end{defn}

\begin{defn}[]
    La covariance 
    \[
        cov(X,Y) = E[(X-E(X))(Y-E(Y))]
    .\]
\end{defn}

\begin{defn}[Coefficient de corrélation linéaire ]
    Soit X,Y deux variables. Le coefficient de corrélation linéaire entre X et Y est:
    \[
        r = \frac{cov(X,Y)}{\sigma _X \sigma _Y}
    .\]
\end{defn}

CCL:
\begin{itemize} VOIR DIAPO
    \item Probabilité
    \item Marginalisation
    \item Conditionnement
    \item Indépendance : Si $ X_1 $ et $ X_2 $ sont indépendantes : $ P(X_1, X_2) = P(X_1)P(X_) $ 
\end{itemize}

\underline{Nouveau cours du 20/09} \\
\begin{defn}[Indépendance de deux variables discrète]
    Discrète : 
    Continue : 
\end{defn}
\begin{defn}[Indépendance mutuelle de $ n $ variable]
    Soient $ n $ variables aléatoires $ (X_1, ..., X_n) $. Elle sont \textbf{mutuellement indépendantes} si tout événement lié à une partie d'entre elles est indépendant de tout événement lié à toute autre partie disjointe de la précédente.
    Propriété : \begin{itemize}
        \item Indépendance mutuelle $\rightarrow$ Indépendance deux à deux. \textbf{Attention:} réciproque fausse
    \end{itemize}

    $\rightarrow$ Permet de réduire la taille du tableau des probabilité de chaque événement !
\end{defn}

\begin{defn}[Indépendance conditionnelles]
    On reprend les formules de l'indépendances mais en sachant une variable, au final c'est dans un cas particulier. 
    \begin{align*}
        X \bot Y | Z \\
        \forall x, \forall y, \forall z P(X=x \cap  Y=y | Z = z) = P(X=x|Z=z) * P(Y=y|Z=z)
    \end{align*}
    $\rightarrow$ 
    \[
        \Rightarrow P(X,Y | Z) = P(X|Z)*P(Y|Z)
    .\]
\end{defn}

\begin{defn}[]
    Loi normale 
    \begin{prop}[]
        - Moyenne linéaire et variance comme bilinéaire
        \[
            X \sim \mathcal{N}(\mu , \sigma ^2) \text{ alors } Y = aX + b \sim \mathcal{N}(a \mu + b , a^2 \sigma ^2)
        .\]
        - Centrer et réduire 
        \[
            Z = \frac{X - \mu }{\sigma } \sim \mathcal{N}(0,1)
        .\]
        
    \end{prop}
\end{defn}

\begin{defn}[Convergence en loi]
    \[
        \forall x, \lim_{n \to \infty} F_n(x) = F(x)
    .\]
    On ne sais pas comment ça converge
\end{defn}

\begin{defn}[Convergence en probabilité]
    $ (X_n) $ \textbf{converge en probabilité} vers $ X $ si, pour tout $ \epsilon > 0 $ la probabilité que l'écart absolu entre $ X_n $ et $ X $ dépasse $ \epsilon  $ tend vers 0 quand $ n \to \infty  $ 
    \[
        \lim_{n \to \infty} P(|X_n-X|\geq \epsilon ) = 0
    .\]
\end{defn}

\begin{defn}[convergence presque sur]
    $ (X_n) $ \textbf{converge presque surement}vers X s'il y a yne proba 1 que la suite des réalisation des $ X_n $ tende vers $ X $ 
\end{defn}

\begin{defn}[Loi faible des grands nombre]
    Soit $ (X_n)_{n \in \mathbb{N}} $ est une suite de variables aléatoires :\begin{itemize}
        \item De même loi
        \item D'éspérance $ m $ 
        \item Possédant une variance $ \sigma ^2 $ 
        \item \textbf{Deux à deux} indépendante
    \end{itemize}
    Alors 
    \[
        \bar{X_n} = \frac{\sum_{k=1}^{n} X_k}{n}  \to _\mathbb{P} m
    .\]
    Rappel : 
    \begin{align*}
        E(\bar{X_n}) &= m \\
        V(\bar{X_n}) &= \frac{\sigma ^2}{n}
    \end{align*}
\end{defn}

\begin{defn}[Loi forte des grands nombres]
    Soit $ (X_n)_{n \in \mathbb{N}} $ est une suite de variables aléatoires :\begin{itemize}
        \item De même loi
        \item D'éspérance $ m $ 
        \item Possédant une variance $ \sigma ^2 $ 
        \item \textbf{mutuellement} indépendante
    \end{itemize}
    Alors 
    \[
        \bar{X_n} = \frac{\sum_{k=1}^{n} X_k}{n} \to _{p.s} m
    .\]
\end{defn}

\begin{defn}[Théorème centrale limite]
    Soit $ (X_n)_{n \in \mathbb{N}} $ est une suite de variables aléatoires :\begin{itemize}
        \item De même loi
        \item D'éspérance $ \mu  $ 
        \item Possédant une variance $ \sigma ^2 $ 
        \item \textbf{mutuellement} indépendantes
    \end{itemize}
    Alors 
    \[
        \frac{\bar{X_n} - \mu }{\sigma / \sqrt[]{n}} \to_{loi} \mathcal{N}(0,1)
    .\]
\end{defn}

\underline{Nouveau cours du 27/09} \\

\section{Maximum Vraissemblance}

\begin{defn}[Vraissemblance d'un échantillon]
    Soit $ x = (x_1, \dots, x_n) $ réalisation de $ (X_1, \dots, X_n) $  \textbf{iid = Mutuellement indépendant}
    Alors on défini la vraisemblance dans le cas discret comem étant la proba d'obtenir \textbf{cet} échantillon sachant la loi P
    \[
        L(x) = P(X_1=x_1, \dots, X_n= x_n ) = \prod_{i=1}^{n}P(X_i = x_i)
    .\]
    Dans le cas continue :
\end{defn}
\begin{exmp}[avec des pièces de monnaies]
    DIAPO 5
\end{exmp}
\begin{exmp}[innondation]
    3 type de parcelles : Inondables (PI), partiellement inondables (PPI), non inondable (NI)
    On a deux loi caractérisant le niveau de gris par rapport à la catégorie d'inondation.
    \[
        P(n | PI) = \mathcal{N}(\mu _1, \sigma ^2_1), P(n|PPI) = \mathcal{N}(\mu _2, \sigma ^2_2)
    .\]
    Avec $ n $ le niveau de gris.

    Soit une image $ Z $ avec un niveau de gris $ n=80 $; Deux hypothèses \begin{itemize}
        \item $ \theta _1 $ $ Z $ PI
        \item $ \theta _2 $ $ Z $ PPI
    \end{itemize}
    On vas calculer le max de vraisemblance d'obtenir la zone Z sous $ \theta 1 $ ou $ \theta 2 $  
    
\end{exmp}

\subsection{Maximum de vraissemblance}
\begin{exmp}[Pièce de monnaie]
    On vas faire la même chose mais cette fois ci, on prend des paramètre $ \theta _1 et \theta _2 $
\end{exmp}

\begin{defn}[Vraissemblance d'un échantillon]
    On cherche à estimer un paramètre $ \Theta  $ 
    Soit $ x = (x_1, \dots, x_n) $ réalisation de $ (X_1, \dots, X_n) $  \textbf{iid = Mutuellement indépendant}
    Alors on défini la vraisemblance dans le cas discret comme étant la proba d'obtenir \textbf{cet} échantillon sachant la loi P
    \[
        L(x) = P(X_1=x_1, \dots, X_n= x_n | \Theta = \theta ) = \prod_{i=1}^{n}P(X_i = x_i | \Theta = \theta )
    .\]
    On peut utiliser la fonction de densité.
\end{defn}

\begin{defn}[Maximum vraissemblance]
    On cherche le maximum de la fonction $ L(x, \theta ), \forall \theta $. Donc on vas la dériver ! et utiliser le $ \log_{}  $ 
\end{defn}

\begin{exmp}[]
    Plein d'exemple dans le diapo
\end{exmp}

\begin{exmp}[problème d'ajustement]
    On a des points un peu random, réparti comme un sinusoide qu'on vas approximé par un polynome. Problème : on a une erreur Normale.

    il vas vite. Mais ça resemble à une regression.
\end{exmp}

\subsection{Estimation par maximum a posteriori}
\begin{exmp}[Pièce de monnaie]
    Imaginons qu'on a un tirage de 3 piles. Le maximum de vraisemblance vaut 1. Mais ça va à l'encontre du bon sens. $\rightarrow$ Solution : Maximum a posteriori. (A voir pourquoi ça fait 1)
\end{exmp}

\begin{defn}[Maximum a posteriori]
    On se base dans un modèle bayésien avec \begin{itemize}
        \item $ \mathcal{X}= $ l'espace des observations $ x $ de taille $ n $ 
        \item $ \Theta  $ 
    \end{itemize}
    
    \[
        \text{ Formile de la vraissemblance diapo 32}
    .\]
    Estimateur du maximum a posteriori toujours égal à l'argmax de la vraissemblance 
    \[
        x \mapsto t = Argmax_{\theta \in \Theta } \pi (\theta |x)
    .\]
    
\end{defn}
\begin{exmp}[pièce de monnaie]
    En faite la grosse différence c'est la dernière ligne du diapo 34. On pose, on invente l'information a priori de la proba de chaque paramètre qu'on vas tester. Cette information vas permettre d'être utiliser dans le modèle bayésien. On l'a choisi en fonction d'une loi normale. Fin du cours sans qu'il ait fini.
\end{exmp}























\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage[french]{babel}

\usepackage[default,scale=0.95]{opensans}
\usepackage[T1]{fontenc}
\usepackage{amssymb} %math
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{systeme}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={MAPSI},
    % pdfpagemode=FullScreen,
    }
\urlstyle{same} %\href{url}{Text}

\theoremstyle{plain}% default
\newtheorem{thm}{Théorème}[section]
\newtheorem{lem}[thm]{Lemme}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollaire}
%\newtheorem*{KL}{Klein’s Lemma}

\theoremstyle{definition}
\newtheorem{defn}{Définition}[section]
\newtheorem{exmp}{Exemple}[section]
% \newtheorem{xca}[exmp]{Exercise}

\theoremstyle{remark}
\newtheorem*{rem}{Remarque}
\newtheorem*{note}{Note}
%\newtheorem{case}{Case}



\title{Cours: MAPSI}
\author{Charles Vin}
\date{2022}

\begin{document}
\maketitle
\underline{Nouveau cours du 13/09} \\
\section{Introduction}

\begin{itemize}
    \item Exam final : 50\%
    \item Partiel : 35\%
    \item Participation : 15\%
    \begin{itemize}
        \item travail dans la séance
        \item TME soumis en fin de séance omg 
    \end{itemize}
\end{itemize}

Deux grand type de modèle : \begin{itemize}
    \item Modèle paramétrique : connaissance sur la distribution stat des données. Puis on estime les paramètres de la loi.
    \item Modèle non paramétrique : l'inverse, on ne connait pas la loi. exemple : regression logistique
\end{itemize}

Echantillons : \begin{itemize}
    \item population
    \item ect 
\end{itemize}

\begin{defn}[]
    Vocabulaire :   
    \begin{itemize}
        \item Voir diapo 9/51
    \end{itemize}
\end{defn}

\begin{defn}[Mesure de proba]
    Une fonction qui associe chaque événement à une valeur entre 0 et 1.
    Voir diapo 15, definition importante.
\end{defn}

\begin{defn}[]
    \[
        P(A \cup B) = P(A) + P(B) - P(A \cap B)
    .\]
    Densité de proba 
    \[
        \text{Retrouver la définition}
    .\]
    
    Fonction de répartition
    \[
        F(x) = P(X<x) = \int_{-\infty }^{x}f(x)dx
    .\]
    Espérance : \begin{align*}
        E(X) &= \sum_{}^{}x_k*p_k \\
        E(X) &= \int_{}^{}X p(x) dx \\ 
        E(aX+b) = aE(X) + b \\
        E(X + Y) = E(X)+E(Y)
    \end{align*}

    Le Mode \begin{align*}
        p(Mo) = \max _k p(x_k)
        p(Mo) = \max _x p(x)
    \end{align*}

    Variance : \begin{align*}
        \sigma ^2 = \sum_{}^{}(x_k - E(X))^2 \\
        \sigma ^2 = \int_{}^{}(x-E(X))^2 p(x)dx \\
        V(aX+b) = a^2V(X) \\
        V(X) = E(X^2) - E(X)
    \end{align*}

    Médiane et quantile \begin{align*}
        \text{idk diapo}
    \end{align*}
\end{defn}

\begin{defn}[Loi marginale]
    La marginalisation consiste à projeter une loi jointe sur l'une des variables aléatoires. Par exemple extraire $ P(A) $ à partir de $ P(A,B) $. 
    \[
        P(A) = \sum_{i}^{}P(A, B = p b_i)
    .\]
    C'est la somme de la ligne ou de la colonne du tableau.
\end{defn}

\begin{defn}[]
    Probabilités conditionnelles
    \begin{align*}
        &P(A|B) = \frac{P(A \cup B)}{P(B)} \\ 
        \Leftrightarrow& P(A \cup B) = P(A|B)P(B)
    \end{align*}
    \begin{prop}[]
        \begin{itemize}
            \item Réversibilité : $ P(A,B) = P(A|B) $
            \item Théorème de Bayes : 
            \[
                P(A|B) = \frac{P(B|A)P(A)}{P(B)}
            .\]
            \item Intégration des probabilités totale
            \item DIAPO 39
        \end{itemize}
    \end{prop}    
    
\end{defn}

\begin{defn}[Indépendance probabiliste]
    Deux événements A et B sont indépendants si 
    \[
        P(A,B) = P(A) * P(B)
    .\]
    Corollaire : $ P(A|B) = P(A) $ 
\end{defn}

\begin{defn}[]
    La covariance 
    \[
        cov(X,Y) = E[(X-E(X))(Y-E(Y))]
    .\]
\end{defn}

\begin{defn}[Coefficient de corrélation linéaire ]
    Soit X,Y deux variables. Le coefficient de corrélation linéaire entre X et Y est:
    \[
        r = \frac{cov(X,Y)}{\sigma _X \sigma _Y}
    .\]
\end{defn}

CCL: VOIR DIAPO
\begin{itemize} 
    \item Probabilité
    \item Marginalisation
    \item Conditionnement
    \item Indépendance : Si $ X_1 $ et $ X_2 $ sont indépendantes : $ P(X_1, X_2) = P(X_1)P(X_) $ 
\end{itemize}

\underline{Nouveau cours du 20/09} \\
\begin{defn}[Indépendance de deux variables discrète]
    Discrète : 
    Continue : 
\end{defn}
\begin{defn}[Indépendance mutuelle de $ n $ variable]
    Soient $ n $ variables aléatoires $ (X_1, ..., X_n) $. Elle sont \textbf{mutuellement indépendantes} si tout événement lié à une partie d'entre elles est indépendant de tout événement lié à toute autre partie disjointe de la précédente.
    Propriété : \begin{itemize}
        \item Indépendance mutuelle $\rightarrow$ Indépendance deux à deux. \textbf{Attention:} réciproque fausse
    \end{itemize}

    $\rightarrow$ Permet de réduire la taille du tableau des probabilité de chaque événement !
\end{defn}

\begin{defn}[Indépendance conditionnelles]
    On reprend les formules de l'indépendances mais en sachant une variable, au final c'est dans un cas particulier. 
    \begin{align*}
        X \bot Y | Z \\
        \forall x, \forall y, \forall z P(X=x \cap  Y=y | Z = z) = P(X=x|Z=z) * P(Y=y|Z=z)
    \end{align*}
    $\rightarrow$ 
    \[
        \Rightarrow P(X,Y | Z) = P(X|Z)*P(Y|Z)
    .\]
\end{defn}

\begin{defn}[]
    Loi normale 
    \begin{prop}[]
        - Moyenne linéaire et variance comme bilinéaire
        \[
            X \sim \mathcal{N}(\mu , \sigma ^2) \text{ alors } Y = aX + b \sim \mathcal{N}(a \mu + b , a^2 \sigma ^2)
        .\]
        - Centrer et réduire 
        \[
            Z = \frac{X - \mu }{\sigma } \sim \mathcal{N}(0,1)
        .\]
        
    \end{prop}
\end{defn}

\begin{defn}[Convergence en loi]
    \[
        \forall x, \lim_{n \to \infty} F_n(x) = F(x)
    .\]
    On ne sais pas comment ça converge
\end{defn}

\begin{defn}[Convergence en probabilité]
    $ (X_n) $ \textbf{converge en probabilité} vers $ X $ si, pour tout $ \epsilon > 0 $ la probabilité que l'écart absolu entre $ X_n $ et $ X $ dépasse $ \epsilon  $ tend vers 0 quand $ n \to \infty  $ 
    \[
        \lim_{n \to \infty} P(|X_n-X|\geq \epsilon ) = 0
    .\]
\end{defn}

\begin{defn}[convergence presque sur]
    $ (X_n) $ \textbf{converge presque surement}vers X s'il y a yne proba 1 que la suite des réalisation des $ X_n $ tende vers $ X $ 
\end{defn}

\begin{defn}[Loi faible des grands nombre]
    Soit $ (X_n)_{n \in \mathbb{N}} $ est une suite de variables aléatoires :\begin{itemize}
        \item De même loi
        \item D'éspérance $ m $ 
        \item Possédant une variance $ \sigma ^2 $ 
        \item \textbf{Deux à deux} indépendante
    \end{itemize}
    Alors 
    \[
        \bar{X_n} = \frac{\sum_{k=1}^{n} X_k}{n}  \to _\mathbb{P} m
    .\]
    Rappel : 
    \begin{align*}
        E(\bar{X_n}) &= m \\
        V(\bar{X_n}) &= \frac{\sigma ^2}{n}
    \end{align*}
\end{defn}

\begin{defn}[Loi forte des grands nombres]
    Soit $ (X_n)_{n \in \mathbb{N}} $ est une suite de variables aléatoires :\begin{itemize}
        \item De même loi
        \item D'éspérance $ m $ 
        \item Possédant une variance $ \sigma ^2 $ 
        \item \textbf{mutuellement} indépendante
    \end{itemize}
    Alors 
    \[
        \bar{X_n} = \frac{\sum_{k=1}^{n} X_k}{n} \to _{p.s} m
    .\]
\end{defn}

\begin{defn}[Théorème centrale limite]
    Soit $ (X_n)_{n \in \mathbb{N}} $ est une suite de variables aléatoires :\begin{itemize}
        \item De même loi
        \item D'éspérance $ \mu  $ 
        \item Possédant une variance $ \sigma ^2 $ 
        \item \textbf{mutuellement} indépendantes
    \end{itemize}
    Alors 
    \[
        \frac{\bar{X_n} - \mu }{\sigma / \sqrt[]{n}} \to_{loi} \mathcal{N}(0,1)
    .\]
\end{defn}

\underline{Nouveau cours du 27/09} \\

\section{Maximum Vraissemblance}

\begin{defn}[Vraissemblance d'un échantillon]
    Soit $ x = (x_1, \dots, x_n) $ réalisation de $ (X_1, \dots, X_n) $  \textbf{iid = Mutuellement indépendant}
    Alors on défini la vraisemblance dans le cas discret comem étant la proba d'obtenir \textbf{cet} échantillon sachant la loi P
    \[
        L(x) = P(X_1=x_1, \dots, X_n= x_n ) = \prod_{i=1}^{n}P(X_i = x_i)
    .\]
    Dans le cas continue :
\end{defn}
\begin{exmp}[avec des pièces de monnaies]
    DIAPO 5
\end{exmp}
\begin{exmp}[innondation]
    3 type de parcelles : Inondables (PI), partiellement inondables (PPI), non inondable (NI)
    On a deux loi caractérisant le niveau de gris par rapport à la catégorie d'inondation.
    \[
        P(n | PI) = \mathcal{N}(\mu _1, \sigma ^2_1), P(n|PPI) = \mathcal{N}(\mu _2, \sigma ^2_2)
    .\]
    Avec $ n $ le niveau de gris.

    Soit une image $ Z $ avec un niveau de gris $ n=80 $; Deux hypothèses \begin{itemize}
        \item $ \theta _1 $ $ Z $ PI
        \item $ \theta _2 $ $ Z $ PPI
    \end{itemize}
    On vas calculer le max de vraisemblance d'obtenir la zone Z sous $ \theta 1 $ ou $ \theta 2 $  
    
\end{exmp}

\subsection{Maximum de vraissemblance}
\begin{exmp}[Pièce de monnaie]
    On vas faire la même chose mais cette fois ci, on prend des paramètre $ \theta _1 et \theta _2 $
\end{exmp}

\begin{defn}[Vraissemblance d'un échantillon]
    On cherche à estimer un paramètre $ \Theta  $ 
    Soit $ x = (x_1, \dots, x_n) $ réalisation de $ (X_1, \dots, X_n) $  \textbf{iid = Mutuellement indépendant}
    Alors on défini la vraisemblance dans le cas discret comme étant la proba d'obtenir \textbf{cet} échantillon sachant la loi P
    \[
        L(x) = P(X_1=x_1, \dots, X_n= x_n | \Theta = \theta ) = \prod_{i=1}^{n}P(X_i = x_i | \Theta = \theta )
    .\]
    On peut utiliser la fonction de densité.
\end{defn}

\begin{defn}[Maximum vraissemblance]
    On cherche le maximum de la fonction $ L(x, \theta ), \forall \theta $. Donc on vas la dériver ! et utiliser le $ \log_{}  $ 
\end{defn}

\begin{exmp}[]
    Plein d'exemple dans le diapo
\end{exmp}

\begin{exmp}[problème d'ajustement]
    On a des points un peu random, réparti comme un sinusoide qu'on vas approximé par un polynome. Problème : on a une erreur Normale.

    il vas vite. Mais ça resemble à une regression.
\end{exmp}

\subsection{Estimation par maximum a posteriori}
\begin{exmp}[Pièce de monnaie]
    Imaginons qu'on a un tirage de 3 piles. Le maximum de vraisemblance vaut 1. Mais ça va à l'encontre du bon sens. $\rightarrow$ Solution : Maximum a posteriori. (A voir pourquoi ça fait 1)
\end{exmp}

\begin{defn}[Maximum a posteriori]
    On se base dans un modèle bayésien avec \begin{itemize}
        \item $ \mathcal{X}= $ l'espace des observations $ x $ de taille $ n $ 
        \item $ \Theta  $ 
    \end{itemize}
    
    \[
        \text{ Formile de la vraissemblance diapo 32}
    .\]
    Estimateur du maximum a posteriori toujours égal à l'argmax de la vraissemblance 
    \[
        x \mapsto t = Argmax_{\theta \in \Theta } \pi (\theta |x)
    .\]
    
\end{defn}
\begin{exmp}[pièce de monnaie]
    En faite la grosse différence c'est la dernière ligne du diapo 34. On pose, on invente l'information a priori de la proba de chaque paramètre qu'on vas tester. Cette information vas permettre d'être utiliser dans le modèle bayésien. On l'a choisi en fonction d'une loi normale. Fin du cours sans qu'il ait fini.
\end{exmp}

\underline{Nouveau cours du 04/10} \\

\section{Principes d'apprentissage avec donnée manquantes}
\begin{itemize}
    \item Solution ez : Supprimer les lignes avec des données manquantes. Problème, ça peut changer les probabilités qu'on peut apprendre.
    \item Remplacer les valeurs manquante par les plus probable : C'est équivalent à l'algo des K-Means. Mais pareil ça change les probas. Mais la valeur la plus probable peut quand même valoir 15\% si notre variables aléatoire peut prendre beaucoup de valeur. 
    \item Replacer les valeurs manquante par toutes les valeurs possible : marche pas non plus. 
    \item Tenir compte de la distribution des valeur : mais ça change encore X 
    \item \textbf{Solution algo EM :}Replacer les valeurs manquante par toutes les valeurs possible ponderers par leur probabilité d'apparition. Cette fois-ci les proba sont équivalente entre les deux tableaux. 
\end{itemize}
Idée de K-MEans et EM : 
\begin{itemize}
    \item Se donner un modèle initial (pas trop mauvais)
    \item Ce modèle $\rightarrow$ Donne des données complètés
    \item Apprendre un nouveau modèle avec ces données
    \item Boucle
\end{itemize}
Y'a-t-il convergence ? 

\subsection{L'algorithme EM}

Notation : 
\begin{itemize}
    \item $ x^o $  données observées, $ x^h $ données manquantes, $ x = x^o \cup x^h $ 
    \item $M_{ij} = P(r_i^j \in x^h)$ proba de position des données manquantes
\end{itemize}

Plusieurs cas sur les proba de missing data : 
\begin{itemize}
    \item Missing Completely at Random (MCAR) : $P(M|x) = P(M)$ Aucune relation entre le fait qu'une donnée soit manquante ou observée
    \item Missing at Random (MAR) : $P(M|x) = P(M|xo)$ données manquantes en relation avec les données observées mais pas avec les autres données manquantes
    \item Not Missing At Random (NMAR) : $P(M|x)$ données   manquantes en relation avec toutes les données
\end{itemize}
On vas regarder que \textbf{MCAR}.

On calcule une log vraissemblance sur les données observées
\begin{align*}
    \log_{} L(x^o, \Theta ) = \sum_{i=1}^{n}\log_{} P(x_i^o | \Theta ) = \sum_{i=1}^{n}\log_{} (\sum_{x_i^h \in x^h}^{}P(x_i^o, x_i^h | \Theta ))
\end{align*}
On fait apparaitre les $ x^h $ avec la formule de somme loi marginale. Rappel : on leur a donnée des probas manuellement. 

Soit $ Q_i(x_i^h) $ une loi de proba \textbf{quelconque} alors on peut l'insérer dans l'équation pour ensuite utiliser l'équation de Jensen des fonction convexe/concave. Comme ça on vas pouvoir sortir la somme du log. 

Bref, pour plus de détail sur les math voir le diapo, finalement on arrive diapo 16. 

Algo EM : \begin{enumerate}
    \item Choisir valeur initale 
    \item \textbf{Pour chaque ligne}, je fais le calcul diapo 17 
    \item Maximisation 
    \item Boucle tant que pas de convergence
\end{enumerate}
En faite on converge vers un optimum \textbf{local} qui dépend du point initial. Donc du coup on en test plein 

\begin{exmp}[]
    DIAPO 18
    \begin{enumerate}
        \item On est pas obligé de faire cette méthode d'initialisation. C'est juste une sorte d'indication mais au final on défini encore en random après 
        \item 
    \end{enumerate}
\end{exmp}

Pourquoi ça converge ? Grace à l'inégalité de Jensen et la concavité du log. Voir diapo 26 et 27. 

\section{Mixure de gaussiennes}
Les données suivent plusieurs gaussienne différente ? 

\begin{exmp}[application : apprentissage de prix fonciers]
    On a un échantillon de prix de logement avec leur caractéristique et le quartier. Le prix est sur une gaussienne de paramètre variant en fonction du quartier. (Je suis pas sur de si on a l'info sur le quartier, je crois on cherche à la prédire avec de l'apprentissage non-supervisé)

    On peut tenter de calculer directement ça je crois mais bref ça marche pas, pas de solution analytiquement. Solution $\rightarrow$ EM 

    On créer une colonne vide, pleine de valeur manquante pour le quartier et on vas faire EM dessus. C'est assez drôle on créer des données à partir de rien. 
\end{exmp}

\begin{exmp}[Classification d'image]
    Deux dernière diapo
\end{exmp}


\underline{Nouveau cours du 11/10} \\

\section{Tests d'hypothèses}

tout comme l'année dernière 

\underline{Nouveau cours du 18/10} \\

\section{Chaine de Markov}
Cette fois-ci on vas pas utiliser des données sous forme matriciel iid. Ici on vas s'intéresser à des modèles de séquences, qui ont une dynamique temporelle. Application :
\begin{itemize}
    \item Musique/reconnaissance de paroles
    \item Reconnaissance de mouvement 
    \item Diffusion dans les graphes
\end{itemize}

Problème : Les méthodes standard de classification = données de tailles fixes $\rightarrow$ transition difficile vers des données de taille variable

Diapo 6/45 
\begin{enumerate}
    \item $ \Leftrightarrow $ vraissemblance
    \item .
    \item proba à posteriori
\end{enumerate}
Faire de l'apprentissage d'un modèle de séquence $ \Leftrightarrow $ apprendre une fonction de densité. On support toujours les $ \theta _k $ iid (HP forte).

Diapo 9 : \\
Au final on modèlise la dépendance par la chaine de markov. On vas essayer d'associer à une séquence, un label pour prédire la classe. Paramètre du modèle $ \{\Pi, A\} $. Permet de faire des prévision dans les espaces discrets

Diapo 10 : \\
Hypothèse Markovienne : La proba de l'état suivant ne dépend que de $ k $ état d'avant. On prend en général $ k=1 $ : l'état prochain ne dépend uniquement de l'était présent. Si on prend plus ça rajoute beaucoup beaucoup de paramètre.

Diapo 11 : Définition des paramètres \\
On a une matrice de transition $ A = [a_{ij} = p(x_{t+1} = q_j| x_t =q_i)]$ avec la somme des ligne égal à 1 (matrice stochastique). Et $ \Pi =  $ proba d'état initiale

Diapo 14 : Représentation matriciel \\
On peut avoir la proba $ p(x_{t+1} = q_j) $ en un calcul matriciel 
\[
    p_{t+1} = p_t * A
.\]

Diapo 21 : Stationarité
\begin{defn}[]
    Existe-t-il un état stationnaire $ \mu  $ 
    \[
        \mu = \mu A
    .\]
    C'est à dire qu'on 
    \begin{itemize}
        \item Si $ A $ irreductible $\rightarrow \mu $ est unique 
    \end{itemize}
\end{defn}

\begin{defn}[Irréductible finie]
    Si on part d'un état donnée, la probabilité d'y revenir est n on nulle. en un nombre d'étape fini $ \Leftrightarrow $ graphe fortement connexe, pas d'état final/absorbant.
\end{defn}

\begin{defn}[Périodicité]
    Etat périodique de période $ k $ si on peut y revenir en un nombre d'étape multiple de $ k $.

    Période d'une chaine de markov = PGCD de la période de tout ces états. Diapo 23
\end{defn}

\begin{thm}[Ergodique]
    C'est la loi forte des grands nombres pour les chaines de markov. On a convergence vers la moyenne.

    Les chaines irréductible et apériodique sont \textbf{ergodique}
\end{thm}

\section{Apprentissage des paramètres}
Comment apprendre une CM à partir d'exemple ? Comment faire de la classification de séquences avec des CM ? 

On vas maximiser la vraissemblance, mais cette fois on a des contraintes sur les distributions de proba égal à 1 (comme avec la multinomiale). $\rightarrow$ Langrandien 

Il s'est arrêté diapo 34. et rush le reste. Au final c'est comme d'habitude la moyenne d'apparition.

\underline{Nouveau cours du 25/10} \\

\section{Procédure d'évaluation}
Méthode d'évaluation : 
\begin{itemize}
    \item beaucoup de donnnée : On sépare train/Test
    \item Le plus souvent : Cross valisation 
    \item Leave one out : Sur un set de $ N $, on prend $ N-1 $ pour apprendre, et $ 1 $ pour évaluer puis on fait toute les permutations.
\end{itemize}

Diapo 4 : Le risque de overfiting dépends de :
\begin{itemize}
    \item Du nombre de données
    \item Du nombre de paramètre aussi comme dans le TME.
\end{itemize}

\section{Chaine de Markov Cachée}
\begin{itemize}
    \item Séparation des observation et des états : une séquence d'observation, avec chaque observation générée par un état.
    \item Même formalisme que pour la chaine de Markov
    \item Pour les observation, on modélise une matrice d'observation des données $ B $ qui pour chaque état associe une proba d'observer les données. Proba d'observer $ w_i $ dans l'état $ s_i $.
    \item Diapo 10 : en plus de ce qu'on avait avant, Pour une observation $ X_i $ une proba d'être dans l'état $ 1, 2, 3 $ (comme en RL)
    \item Les Hypothèse importante : \begin{itemize}
        \item On a toujours l'hypothèse de Markov 
        \item Les observation successives sont indépendantes conditionnellement aux états. Une observation = dépend d'un état seulement.
    \end{itemize}
    \item Notation $ s^t_1 = s_1, \dots, s_t $ 
\end{itemize}
Trois problèmes pour les POMDP : 
\begin{itemize}
    \item Evaluation : calculer une proba pour une séquence d'observation 
    \item Décodage : Séquence d'observation, quelle séquence d'états a généré les observation
    \item Apprentissage : Trouver les paramètre de mon modèle à partir d'une série d'observation. 
\end{itemize}
Calcul de la proba des observations ? $ P(x_1^T | \lambda ) $ 
\begin{itemize}
    \item Diapo 22 : On peut pas utiliser une proba totale en sommant pour tous les états
    \item $\rightarrow$ On utlise l'HP de Markov, super on peut le faire par récursion, c'est assez cohérent avec le fait qu'on travail sur une chaîne.
    \item Voir diapo pour le détail de la récursion j'ai pas écouté
\end{itemize}

Problème du décodage : 
\begin{itemize}
    \item Même problème que tout à l'heure
    \item Donc on utilise l'HP de Markov
    \item Et on peut retrouver un truc récursif : l'algo de Viterbi
    \item 
\end{itemize}

Problème d'apprentissage : diapo
\begin{itemize}
    \item Gros lien avec EM : Donnée manquante $\rightarrow$ C'est un cas particulier de EM
    \item Algo diapo 32 
    \item Il faut comprendre les deux problèmes précédents
    \item Dans la suite des diapo il détails le même algo mais en plus complexe qui ne donne pas une assignation dur
\end{itemize}

Convergence de la vraissemblance : diapo 44
\begin{itemize}
    \item Le problème c'est qu'on optimise sur une fonction qui n'est pas convexe $\rightarrow$ On risque de tomber sur des max locaux $\rightarrow$ L'algo est sensible à l'initialisation
    \item 
\end{itemize}

En continue : 
\begin{itemize}
    \item On fait pareil pour estimer les paramètres de la loi
\end{itemize}

Exemple d'application : 
\begin{itemize}
    \item NLP dans l'étiquetage morpho-syntaxique (verbe, sujet, ect). Observation : le corpus de mot, Etat : les propriété morpho-syntaxique (sujet, verbe, ect)
    \item Reconnaissance de la paroles : signal audio = donnée séquentiel
    \item Reconnaissance de l'écriture
    \item Segmentation d'image : Mais on passe en 2D :o $\rightarrow$ ca devient super dur à calculer. Idée de chaine n'est plus existante : plus de récursion. Du coup on fait des méthode approximé ou on transforme l'image en un arbre
\end{itemize}


\end{document}
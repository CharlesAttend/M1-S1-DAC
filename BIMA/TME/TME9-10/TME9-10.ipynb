{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical works 9 & 10 : Face recognition by Eigenfaces method\n",
    "\n",
    "\n",
    "**The objective of this practical work is to study the properties of the Eigenfaces face recognition method.**\n",
    "\n",
    "We propose to develop a system capable of:\n",
    "- identify a face from a database of faces \n",
    "- determine whether an image contains a face present in the database\n",
    "- to decide whether an image represents a face or not\n",
    "\n",
    "Tools developed in this practical work will be applied on the Yale Faces Database.\n",
    "\n",
    "## General principle\n",
    "\n",
    "The problem of face recognition is defined as follows: given a face image, one wishes to determine the identity of the corresponding person.\n",
    "To this end, it is necessary to have reference images, in the form of a database of faces of all persons known by the system. \n",
    "Each face is associated to a vector of characteristics. \n",
    "These characteristics are supposed to be invariant for the same person, and different from one person to another one. \n",
    "Face recognition then consists in comparing the vector of characteristics of the face to be recognized with those of each of the faces of the database. \n",
    "This makes it possible to find the person in the database having the most similar face.\n",
    "\n",
    "There are several types of methods, distinguished by the type of characteristics used, see _S.A. Sirohey, C.L. Wilson, and R. Chellappa. Human and machine recognition of faces: A survey. Proceedings of the IEEE, 83(5), 1995_ for a state of the art:\n",
    "\n",
    "- The approaches by face models proceed to a biometric analysis of faces. Pertinent biometrics are the distance between the eyes, length of the nose, shape of the chin...\n",
    "- Image based approaches, by contrast, directly compare faces, considering them as images, for which measures of pre-attentive similarities (without a priori model) are defined.\n",
    "- Hybrid approaches use the notions of similarity between images, but add a priori knowledge about the structure of a face.\n",
    "\n",
    "![principe.png](./figs/Figure_1.png)\n",
    "<center>Figure 1: General Principle of a Face Recognition System</center>\n",
    "\n",
    "## Analysis by Eigenfaces\n",
    "\n",
    "Face recognition by Eigenfaces is an image-based approach. \n",
    "Each face image is considered as a vector in a space having as many dimensions as the number of pixels in the image. \n",
    "The image characteristics are extracted by a method of dimensionality reduction based on principal component analysis (PCA). \n",
    "This approach was originally proposed in 1991, see Mr. Turk and A. Pentland. Eigenfaces for recognition. J. Cognitive Neuroscience, 3(1) :71-86, 1991_.\n",
    "\n",
    "In the following, we will use the italic notation to designate scalars ($m, K,\\dots$) and vectors ($x, u$), and boldface  for the matrices ($\\mathbf X, \\mathbf X_c, \\mathbf W, \\dots$).\n",
    "\n",
    "A face image is noted $x$ and represented as a vector of $d$ components. $x[i] (i=0,\\cdots,d-1)$ is the pixel number $i$ of this image. A set of faces form a cloud of points in the space $\\mathbb{R}^d$. \n",
    "The database is divided into two sets: the *training* or *reference* set, used to learn the faces, and the *test* set, used to test the method. \n",
    "Faces of the training set are denoted by $x_k^{train}$ $(k=0,\\cdots,N_{train}-1)$ and faces of the test set are denoted by $x_k^{test}$ $(k=0,\\cdots,N_{test}-1) (k=0,\\cdots,N_{test}-1)$.\n",
    "\n",
    "We note $x_{average}$ the average of the reference faces, or average face. \n",
    "The principle of the Eigenfaces method is to model the difference of any face in relation to this average face by a linear combination of a limited number of images $u_h$, called Eigenfaces. \n",
    "One image of face $x \\in \\mathbb{R}^d$ is thus expressed as the average face to which is added a linear combination of eigenfaces:\n",
    "\n",
    "$$x = x_{average} + \\sum_h a_h u_h + \\varepsilon$$\n",
    "\n",
    "where $a_h$ represents the weight of *the eigenface* of index $h$ in the face $x$, and $\\varepsilon$ represents the error between $x$ and its approximation by eigenfaces (error is due to the truncation of the basis of eigenvectors). \n",
    "Coefficients $a_h$ play a very important role for face recognition, because they correspond to the face coordinates $x$ in the face subspace.\n",
    "\n",
    "The Eigenfaces method is based on the fact that the number of eigenfaces is much smaller than the total size of the space, which is called dimensionality reduction. In other words, the basis of eigenfaces is truncated, keeping only the vectors coding for the most significant information.\n",
    "The images are therefore analyzed in a sub-space of reduced dimensions, which represents more specifically faces, among all possible types of images.\n",
    "\n",
    "The average face is always the same for a fixed reference database, each face is examined after subtraction of the average face.\n",
    "\n",
    "## Face database\n",
    "\n",
    "We use the Yale Faces image database, http://cvc.cs.yale.edu/cvc/projects/yalefaces/yalefaces.html.\n",
    "In this database, all the faces have been preprocessed, in order to resize and crop them to the size $64\\times64$ pixels, so the images can be compared pixel per pixel.\n",
    "\n",
    "\n",
    "This database contains 120 greyscale images, representing the faces of 15 people. There are 8 images per person, each corresponding to a category of images varying according to the following criteria (see Figure 2):\n",
    "- variation of facial expression: normal, sad, sleepy, surprised,\n",
    "    wink, happy\n",
    "- variation of accessories: glasses, noglasses,\n",
    "\n",
    "![database.png](./figs/Figure_2.png)\n",
    "<center>Figure 2: Illustration of the shooting categories</center>\n",
    "\n",
    "The database is divided into two groups: the reference group will be used as a training set, the other group as a test set: \n",
    "- the reference base contains $n$ images, each with a number of pixels $d=n_l\\times n_c$. There are $6$ images per person in the training database, so $n=6\\times15=90$. Each image is $64\\times64$, hence $d=4096$, \n",
    "- the test base contains $2$ images per person so a total of 30 images. Each image is again $64\\times64$.\n",
    "\n",
    "In the following, we always manipulate face images in the form of vectors, and a set of faces in the form of a matrix where each column is a face. \n",
    "As we use Numpy, the images are stored in a multidimensionnal array of reals (double). \n",
    "This array is viewed as a matrix $\\mathbf X$ of size $d\\times n$: $$\\mathbf X= \\left[ x_0, ..., x_{n-1}\\right]$$.\n",
    "\n",
    "The matrix $\\mathbf X$ is split into $\\mathbf X^{train}$ and $\\mathbf X^{test}$ of size $d\\times N_{train}$ and $d\\times N_{test}$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: loading the database, display and centering of faces\n",
    "\n",
    "Vectors $id$ and $cat$ give information about the images: $id[k]$ and $cat[k]$ are respectively the identification (an index) and the cagetory of face $k$. These vectors are available for the reference and the test bases and will be useful in the following.\n",
    "\n",
    "To load the database, we simply have to read the Matlab file `YaleFaces.mat` provided with this notebook: it provides the matrices and vectors $\\mathbf X^{train}, \\mathbf X^{test}, id^{train}, id^{test}, cat^{train}, cat^{test}$.\n",
    "\n",
    "The following code loads the database and creates the various matrices and vectors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Useful libraries\n",
    "import numpy.linalg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Loading YaleFaces database\n",
    "import scipy.io\n",
    "\n",
    "yaleFaces = scipy.io.loadmat('./YaleFaces.mat')\n",
    "\n",
    "# The training set (90 faces)\n",
    "X_train = yaleFaces['X_train']\n",
    "cat_train = yaleFaces['cat_train'][0]\n",
    "id_train = yaleFaces['id_train'][0]-1\n",
    "\n",
    "# The test set (30 faces)\n",
    "X_test = yaleFaces['X_test']\n",
    "cat_test = yaleFaces['cat_test'][0]\n",
    "id_test = yaleFaces['id_test'][0]-1\n",
    "\n",
    "# Additional images that don't contain faces \n",
    "X_noface = yaleFaces['X_noface']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Write a function that computes the average face $x_{moy}$. \\\n",
    "    Tip: use `mean` function from Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanFaces(X):\n",
    "    \"\"\" Array[d,n] -> Vector[d] \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Write a function that centers the faces. \\\n",
    "    Recall: center means subtract the average face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centeredFaces(X):\n",
    "    \"\"\" Array[d,n]*Vector[d] -> Array[d,n] \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function `deflat()` that takes as argument a face, represented as a vector of 4096 elements, and returns an image of size $64\\times64$. \\\n",
    "   Important: the Yale Faces database has been created in Matlab, for which the matrices are organized column by column. It may be useful to transpose the matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deflat(V):\n",
    "    \"\"\"\" Vector[4096] -> Array[64,64] \"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Display the average face, as well as a few faces with the associated centered faces. Here is an example of the expected result:\n",
    "![Figure_3.png](./figs/Figure_3.png)\n",
    "<center>Figure 3: average face and centering of the database</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Computation of Eigenfaces (PCA)\n",
    "\n",
    "\n",
    "The method developed by Turk and Pentland defines the eigenfaces as the main axes obtained by carrying out a principal component analysis (PCA) of the vectors associated with the reference faces. \n",
    "**The eigenfaces are thus the eigenvectors of the covariance matrix $\\mathbf X_c\\mathbf X_c^\\top$**, of size $d\\times d$ , where the matrix $\\mathbf X_c$ of the same size as $\\mathbf X$ represents all the centered faces:\n",
    "$$\\mathbf X_c= \\left[ x_0-x_{moy}, \\cdots x_{n-1}-x_{moy}\\right]$$\n",
    "Each line of $\\mathbf X_c$ corresponds to a pixel $p$, each column of $\\mathbf X_c$ corresponds to a reference face of index $k$.\n",
    "\n",
    "Rather than using eigenvalue decomposition, we will use singular value decomposition (SVD). \n",
    "The SVD decomposes the matrix $\\mathbf X_c$ of size $d\\times n$ into 3 matrices $\\mathbf U$, $\\mathbf S$, $\\mathbf V$ such as :\n",
    "\n",
    "$$\\mathbf X_c=\\mathbf U \\mathbf S\\mathbf V^\\top$$\n",
    "\n",
    "where $\\mathbf U$ and $\\mathbf V$ are orthogonal matrices ($\\mathbf U \\mathbf U^\\top=\\mathbf U^\\top \\mathbf U=\\mathbf I_d^d$ and $\\mathbf V \\mathbf V^\\top=\\mathbf V^\\top \\mathbf V=\\mathbf I_d^n$) of respective sizes $d\\times d$ and $n\\times n$, and $\\mathbf S$ is a matrix of size $d\\times n$ with null elements everywhere except on the main diagonal.\n",
    "\n",
    "This decomposition has the following properties:\n",
    "- the columns of $\\mathbf V$ are the eigenvectors of $\\mathbf X_c^\\top\\mathbf X_c$, \n",
    "- the columns of $\\mathbf U$ are the eigenvectors of $\\mathbf X_c\\mathbf X_c^\\top$,\n",
    "- the matrix $\\mathbf S$ is diagonal. The diagonal represents the singular values of $\\mathbf X_c$, equal to the square roots of the eigenvalues $\\lambda_k$ of $\\mathbf X_c^\\top\\mathbf X_c$ and\n",
    "    $\\mathbf X_c\\mathbf X_c^\\top$. \n",
    "\n",
    "With Numpy, the SVD can be calculated by this way:\n",
    "\n",
    "`U, S, V = numpy.linalg.svd(Xc)`\n",
    "\n",
    "In our case, $n<d$, and the eigenvalues $\\lambda_k$ of $\\mathbf X_c\\mathbf X_c^\\top$ are therefore all null for $k>n$.\n",
    "We will not need the associated eigenvectors $k>n$. \n",
    "The `svd` function has a fast mode, which calculates only the eigenvectors corresponding to the columns of the matrix passed as argument:\n",
    "\n",
    "`U, S, V = svd(Xc, full_matrices=False)`\n",
    "\n",
    "\n",
    "This command returns the matrices $\\mathbf U$ and $\\mathbf V$, of size $d\\times n$ and $n\\times n$, and the matrix $\\mathbf U$ matrix has been truncated, only the first $n$ columns are retained:\n",
    "$$\\mathbf U= \\left[ u_1, \\cdots, u_n\\right]$$\n",
    "Finally `S` is a vector of size $n$ and represents the diagonal matrix $\\mathbf S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function `eigenfaces(Xc)` which returns a t-uple consisting of the $\\mathbf U$ matrix of eigenfaces, computed from a centered database $\\mathbf X_c$, and the table of associated eigenvalues.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenfaces(Xc):\n",
    "    \"\"\" Array[d,n] -> Array[d,n]*Vector[n] \"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use this function to calculate $\\mathbf U$ and $\\mathbf S$. Normalize then the eigenvalues so that their sum is equal to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Display the average face and the first 15 eigenfaces (see figure 4, use the `plt.subplot()` function).\n",
    "   and their associated own values. Give your interpretation of the eigenfaces images?\n",
    "\n",
    "![Figure_4.png](./figs/Figure_4.png)\n",
    "<center>Figure 4: the 15 first eigenfaces</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the curve of the cumulative sum of the normalized eigenvalues (see Figure 5 for the expected result), to see how much variation is captured by the first $K$ eigenfaces. How many eigenfaces are needed to obtain a good reconstruction?    \n",
    "    \n",
    "![Figure_5.png](./figs/Figure_5.png)\n",
    "<center>Figure 5: cumulative sum of eigenvalues</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: projection in the subspace of faces\n",
    "\n",
    "\n",
    "In the following, we use a reduced number of eigenfaces/eigenvectors. The vectorial space of faces, $\\mathbf W_K$, is spanned by the basis formed with the $K$ first eigenvectors:\n",
    "\n",
    "$$\\mathbf W_K = \\left[ u_1, ..., u_K\\right]$$\n",
    "\n",
    "Note that the set of columns of $W_K$ is an orthonormal basis, so $\\mathbf W^\\top_K\\times \\mathbf W_K=\\mathbf I_d^K$.\n",
    "\n",
    "The **projection of a face image $x$ in the face subspace** is simply done by subtracting from $x$ the average face and applying the scalar product with each eigenvector. \n",
    "This gives the coordinates of the image $x$ in the subspace of faces, which is of dimension $K$.\n",
    "\n",
    "Each face therefore has several representations:\n",
    "-   the original image, a vector $x \\in \\mathbb{R}^n$\n",
    "-   the coordinates of the projected image $z$ in the basis of eigenfaces,\n",
    "    $\\left\\lbrace a_h\\right\\rbrace$,\n",
    "    $h \\in\\left\\lbrace 1;K\\right\\rbrace$ (subspace of faces):\n",
    "    $$z = \\mathbf W_K^\\top (x-x_{average})$$\n",
    "-   its reconstruction in the original space $\\mathbb{R}^n$,\n",
    "    $\\tilde{x}$:\n",
    "    $$\\tilde{x} = x_{average} + \\sum_h a_h u_h = x_{moy} + \\mathbf W_K  z$$\n",
    "\n",
    "**The reconstruction error is defined** as the distance between a face $x$ and the associated reconstruction $\\tilde x$:\n",
    "$$E^{recons}(x) =\\|x-\\tilde{x}\\|_2  = \\sqrt{\\sum_{p=1}^n \\left( x(p) - \\tilde{x}(p)\\right) ^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function `projEigenfaces()` which takes as arguments a face, $x$, the average face, $x_{average}$, the subspace of faces $\\mathbf W$, the number of eigenfaces $K$, and  computes the coordinates of projected face $z$ in the subspace $\\mathbf W_K$ of faces.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projEigenface(x, x_mean, W, K):\n",
    "    \"\"\" Vector[d]*Vector[d]*Array[d,n]*int -> Vector[K] \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Write a function `reconstruct()` which takes as arguments a projected face, $z$, the average face, $x_{average}$, and the truncated subspace of face, $W$ and $K$, and computes the coordinate of $x$ in the original space ($\\mathbb{R}^n$).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(z, x_mean, W, K):\n",
    "    \"\"\"Vector[K]*Vector[d]*Array[d,n]*int -> Vector[d] \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Write a function  `errorReconstruct()` which computes the recontruction error between $\\tilde{x}$ and $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorReconstruct(x_r, x):\n",
    "    \"\"\"Vector[d]*Vector[d] -> double \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Write a function `affiche_Reconstruction()` which displays:\n",
    "    - the original face $x$,\n",
    "    - the reconstructed faces $x_r$ for various values of $K$ (for instance, $K =$ 5, 10, 25, 50, 90)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affiche_reconstruction(x, x_moy, W, listK):\n",
    "    \"\"\" Vector[d]*Vector[d]*Array[d,n]*list[int] -> NoneType \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  Test the previous functions by displaying the projection/reconstruction result for several images (from the training and test bases). Figure 6 shows the result of the reconstruction for image 50 of the training base. For image 55 of the training base, what is the reconstruction error for $K=n=90$? Is the image identical to its reconstruction? Same question for image 17 of the test base.\n",
    "\n",
    "![Figure_6.png](./figs/Figure_6.png)\n",
    "<center>Figure 6: example of reconstruction for image number 50</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Is there a difference between the reconstructions of the faces from the training base and those from the test base? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. __Bonus question__: Plot the evolution of the average error of reconstruction of test faces when $K$ varies from 1 to $N$. Is this evolution consistent with the cumulative sum previously calculated (exercise 2, question 4)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Face recognition and identification\n",
    "\n",
    "Each reference face $x_k^{train}$ has an identity associated with it, in the form of a $id^{train}(k)$ number. In this section we try to identify a face $x^{test}$ from the reference faces.\n",
    "\n",
    "The simplest method is to compare the projection $z^{test}$ of the test face $x^{test}$ with the projection $z_k^{train}$ of each reference image $x_k^{train}$ (see Figure 7). The dissimilarity between the two projected vectors is quantified by the distance in subspace $E_k(x^{test})$:\n",
    "\n",
    "$$E_k(x^{test}) =\\|z^{test}-z_k^{train}\\|_2$$\n",
    "\n",
    "![Figure_7.png](./figs/Figure_7.png)\n",
    "<center>Figure 7: Projection of an image $J$ in the subspace of faces and comparison with a reference face $I_k$, in case $K=2$.<center>\n",
    "\n",
    "This distance is evaluated for each reference face, we can determine the reference face $x_k^{train}$ closest to the test face $x^{test}$. **Its identifier $id^{train}(k)$ then allows for the recognition of the tested face.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  What is the advantage of calculating the distance $E_k(x^{test})$ in the subspace of faces rather than in the original space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Write a function ``computeMatDist()`` which takes as arguments the training set of centered faces, $\\mathbf Xc_{train}$ of size $d\\times N_{train}$, the test set of centered faces, $\\mathbf Xc_{test}$ of size $d\\times N_{test}$, the subspace of eigenfaces, $\\mathbf W$ and $K$, and computes the matrix $D$ of distance between a face of the test set and a face of the training set. $D$ is of size $N_{test} \\times N_{train}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculMatDist(X_train, X_test, W, K):\n",
    "    \"\"\" Array[d,n]*Array[d,m]*Array[d,n]*int -> Array[m,n]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Write a function `identification()` which takes as argument the matrix of distances $D$ (computed by the previous function), the vector of identification of the training set $id^{train}$, and returns the identificaton vector $\\hat{id}^{test}$ of size $N_{test}$ of the elements of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification(D, id_train):\n",
    "    \"\"\" Array[m,n]*Array[n] -> Array[m]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute for $K=30$ the identification rate by comparing $\\hat{id}^{test}$ to $id^{test}$ labels. Then vary $K$, and plot the curve of the number of recognized faces as a function of $K$. Explain the shape of the curve obtained. Which value of $K$ can be taken to have a good recognition and a low calculation time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  **Bonus question**: for $K=30$, calculate for each face of the training set its distance in the subspace $\\mathbf W_K$ from each element of the training set. Display the result as the image of a matrix. Comment the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Bonus question**: What are the minimal and maximal distances between two faces of the same category (i.e. same person)? Between two faces of different categories? If we want to choose a threshold $\\theta$  to detect the presence of an unknown face, which indications do the previous min/max values give us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: face/non-face classification\n",
    "\n",
    "Until now, we focused on comparing facial images with each other. But the method provides information that we have not yet used. In particular, the reconstruction error can be used to verify that an image is indeed an image of a face. When an image contains something other than a face (image of a flower, a person seen in its entirety, a random image...), we can say that it is a non-face (database *noface*).\n",
    "\n",
    "![figure8](./figs/Figure_8.png)\n",
    "<center>Figure 8: illustration of possible cases for classifying an image: case 1,2) $Z$ close to subspace: it is a face 3,4) $Z$ far from subspace: it is not a face, 1) $Z$ is an identified face, case 2) $z$ is an unknown face, case 3) risk of identifying $Z$ as a face when it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  With $K=30$, for each set, training set, test set, and *noface* set, plot the reconstruction error of all the images of each set (this provides 3 plots). Compute the minimal, average, maximal errors for the three sets. Which conclusion can be drawn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Visualize the reconstruction error by displaying the original image and the reconstructed image for 10 images of the face database, and for the 10 images of the noface database. Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Pi√®ces jointes",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

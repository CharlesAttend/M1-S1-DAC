\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage[french]{babel}

\usepackage[default,scale=0.95]{opensans}
\usepackage[T1]{fontenc}
\usepackage{amssymb} %math
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{systeme}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Fiche BIMA},
    % pdfpagemode=FullScreen,
    }
\urlstyle{same} %\href{url}{Text}

\theoremstyle{plain}% default
\newtheorem{thm}{Théorème}[section]
\newtheorem{lem}[thm]{Lemme}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollaire}
%\newtheorem*{KL}{Klein’s Lemma}

\theoremstyle{definition}
\newtheorem{defn}{Définition}[section]
\newtheorem{exmp}{Exemple}[section]
% \newtheorem{xca}[exmp]{Exercise}

\theoremstyle{remark}
\newtheorem*{rem}{Remarque}
\newtheorem*{note}{Note}
%\newtheorem{case}{Case}



\title{Fiche BIMA}
\author{Charles Vin}
\date{Décembre 2022}

\begin{document}
\maketitle
\tableofcontents

Gausienne 2D : $ \sigma _f = \frac{1}{\sigma _s \pi } $ 
\[
    \frac{1}{\sqrt[]{2 \pi \sigma }} e^{- \frac{(x-x_0)^2 + (y-y_0)^2}{2 \sigma ^2}}
.\]
Changement d'échelle : ?

Rotation : 
\[
    P \begin{pmatrix}
        u \\
        v
    \end{pmatrix} = \begin{pmatrix}
        cos \theta & \sin \theta \\
        - \sin \theta & \cos \theta 
    \end{pmatrix} \begin{pmatrix}
        u \\
        v
    \end{pmatrix}
.\]
Changement de variable 2D : \begin{align*}
    f(x,y) = (f_1(u), f_2(t)) \\
    \begin{cases}
    x = f_1(u)\\
    y = f_2(t)\\
    \end{cases} \\
    dxdy = \det (Jacobienne(f))
\end{align*}
Pour inverser les variables : penser au matrice ! 

Généralité : 
\begin{itemize}
    \item Dynamique d'une image : $ L = (k_{max} - k_{min}) + 1 $ 
    \item Changer la dynamique $ [k_{min};k_{max}] \to [I_1, I_2] $  : $ f(k) = \frac{k - k_{min}}{k_{max} - k_{min}} * (I_2 - I_1) + I_1 $ 
    \item Inverser une image : $ L - p_i $ 
    \item Histogramme : compter les pixels de chaque couleurs
    \item Flat hist : $ k' = Int(\frac{k_{max} - k_{min}}{N*M}H_c(k)) $ 
    \item Gray value profile : line plot de la ligne de l'image
\end{itemize}

\section{Digitalisation and subsampling}
SIGNAL pour moi sorry

\section{Filtrage}
\textbf{Pense à retourner $ h $ pour la convolution !!!}
Diamond formula 
\[
    f(t)\delta (t-t_0) = f(t_0)\delta (t - t_0)
.\]
\[
    f(t) \star \delta (t - \tau) = f(t - \tau)
.\]


\section{Edge Detection with filtering}
\begin{itemize}
    \item Un bord dans une image peut ressembler à une marche d'escalier ou à une rampe : il est plus ou moins nette
    \item On regarde la direction du gradient : $ \left\| \nabla f \right\| = \sqrt[]{(\frac{\delta f}{\delta x})^2 + (\frac{\delta f}{\delta y})^2} $ que l'ont normalise $ \frac{\nabla f}{\left\| \nabla f \right\| } $ pour obtenir un vecteur unitaire
    \item Par une méthode mathématique obscure nommée différence finis, on peut approximer les dérivés des images pas une convolution 
\end{itemize}
\subsection{Sobel Edge filter}
\[
    G_x = \begin{bmatrix}
        1 & 0 & -1 \\
        2 & 0 & -2 \\
        1 & 0 & -1 
    \end{bmatrix} = \begin{bmatrix}
        1 \\
        2 \\
        1
    \end{bmatrix} \times \begin{bmatrix}
        1 & 0 & -1
    \end{bmatrix}
.\]

\[
    G_y = G_x^T
.\]


\begin{itemize}
    \item la réponse impulsionnel de Sobel est en faite composé d'une matrice qui approxime la gaussienne et la matrice de dérivation horizontale $ \big(\begin{smallmatrix}
        1 & 0 & -1
    \end{smallmatrix}\big) $ 
    \item $ \left\| G \right\| = \sqrt[]{G_x^2 + G_y^2} $ cette norme est plus forte au niveau des contours (car dérivé d'un escalier $ = + \infty  $ )
\end{itemize}


\subsection{Second order}

\[
    \begin{pmatrix}
        0 & 1 & 0 \\
        1 & -4 & 1 \\
        0 & 1 & 0 \\
    \end{pmatrix} \text{ ou } \begin{pmatrix}
        1 & 1 & 1 \\
        1 & -8 & 1 \\
        1 & 1 & 1 \\
    \end{pmatrix}
.\]
\begin{itemize}
    \item Ici on regarde quand la dérivée seconde s'annule pour trouver le max de la dérivé
    \item On utilise un laplacien pour approximer la matrice hessienne $ \Delta f = \frac{\partial ^2 f}{\partial x^2} + \frac{\partial ^2f}{\partial y^2} $ 
    \item Detecter les passages par zéros : \begin{itemize}
        \item Fenetre 3x3 $\rightarrow$ max et min
        \item zéro crossing = $max > 0, min < 0, max - min > S$
    \end{itemize}
    \item Plus précis et moins sensible à la threshold que gradient
    \item \textbf{Pas} invariant par rotation ! 
    \item Thick edge
    \item bruit ++ $\rightarrow$ filtrage nécessaire $\rightarrow$ \textbf{On peut combiner les deux en une convolution} avec le laplacien de la gaussienne 2D
\end{itemize}

\subsection{Approche pyramidale}
Filtre gaussien $\rightarrow$ subsample 2 $\rightarrow$ filtre $\rightarrow$...
\begin{align*}
    &fe > 2 fmax \text{ (shannon) } \\
    \Leftrightarrow& fe > 2 * \frac{3}{\sigma \pi } \\
    \Leftrightarrow& \frac{\pi }{6}fe > \frac{1}{\sigma } \\
    \Leftrightarrow& \frac{\pi}{6} * \frac{1}{2} > \frac{1}{\sigma } \text{ (1/2 car subsample 2)}\\
    \Leftrightarrow& \frac{12}{\pi } < \sigma 
\end{align*}

\subsection{Canny-Deriche}
Filtre gaussien plus optimisé + implémentation récursive possible pour éviter de faire deux fois la convolution(x et y)

\subsection{Post processing}
\begin{itemize}
    \item Binarization Threshold : thick edge + bruit ou missed detection $\Rightarrow$ Gaussian smoothing 
    \item Gaussian smoothing + Threshold : \begin{itemize}
        \item flou ++ = moins de bruit // thick edge (imprecise localization)
        \item Flou -- = bruit // bonne localisation
    \end{itemize}
    \item Non maxima suppression \begin{itemize}
        \item Arrondie sur une des 8 directions 
        \item Interpolation à partir des deux voisins 
        \item $\rightarrow$ Bord fin 
    \end{itemize}
\end{itemize}


\section{Corner Detection}
\begin{itemize}
    \item Point critique de l'image (local extrema, saddle points) = variation dans une ou plusieurs direction $ \Leftrightarrow det(Hess) = 0 $. Ca c'est la detection basique mais elle est vraiment pas ouf
    \item $\rightarrow$ On vas donc jouer avec la matrice Hessienne
\end{itemize}

\subsection{Moravec keypoint detection}
\subsection{Harris detector}

\[
    R_i(\sigma ) = g_\sigma \star Hess(I) = g_\sigma \star \begin{pmatrix}
        I_x^2 & I_x I_y \\
        I_x I_y & I_y^2
    \end{pmatrix}
.\]
\begin{itemize}
    \item Instinctivement : Dans le voisinage du filtre gaussien, on regarde pour des variations dans deux directions
    \item Les valeurs propre de la matrice Hessien indique les changement dans leurs direction respective $ x $ et $ y $ 
    \item Mauvais sur les changements d'échelles \begin{itemize}
        \item Multiscale Harris detector : On peut le stabiliser en changeant l'échelle $ \sigma  $ du filtre gaussien en fonction de la scale de ??? Puis en choisissant la meilleure valeur de $ R $ comme coin \textbf{pas compris} Bref on change la scale et on choisis le meilleur coin sur toutes les scales testées
        \item Pareil pour Harris-Laplace + harris lapalce = flou gaussien + laplace = on peut combiner comme vu avant, je dirais même plus on peut approximer la combinaison pas une différence de gaussienne
    \end{itemize}
    \item bien pour les scene texturé
\end{itemize}
\begin{proof}[Preuve : ]
    On part du détecteur de Moravec : il cherche des changements de variation dans les 8 directions possibles : coin = changement dans deux directions = $ E_{u,v}(x,y) $ grands. \\
    Forcément une image full bruit aura beaucoup de variation, donc pour éviter ça on vas lisser l'image avec un filtre gaussien.

    Donc on cherche les endroits où $ E_{u,v}(x,y) $ est grand aka on veux maximiser la fonctions et trouver les points critique max.

    Point mathématique : Pour savoir la nature d'un point (critique normalement mais bon je sais pas où on annule le gradient) on regarde si la matrice Hessienne est définie positive/négative. Pour ça on regarde les valeurs propre, si elle sont strictement négative, c'est gagné on a trouvé un maximum local ! Par chance, on a pas besoin de diagonaliser à chaque fois car le determinant ($ = \lambda _1 \lambda _2 $ ) et la trace ($ = \lambda _1 + \lambda _2 $ ) sont invariant par changement de base et \href{http://serge.mehl.free.fr/anx/extremum_hesse.html}{suffise pour déterminer le signe des valeurs propres}. \begin{itemize}
        \item $ \det Hess > 0 $ Valeur propre de même signe \begin{itemize}
            \item $ Trace > 0 $ $\rightarrow$ valeur propre positive $\rightarrow$ minimum local
            \item $ Trace < 0 $ $\rightarrow$ valeur propre negative $\rightarrow$ maximum local
        \end{itemize}
    \end{itemize}

    Finalement en posant $ R = det - k*trace^2 $ on reproduit le même principe. Ce critère permet de comparer $ \lambda _1 $ et $ \lambda _2 $.
    \begin{itemize}
        \item If $ \lambda _1 $  and $ \lambda _2 $  are approximately equal, we note $ \lambda _1 \approx  \lambda _2 = \lambda $ and get 
        \[
        R(x,y) \approx \lambda ^2 - k(4 \lambda ^2) = \lambda ^2 (1 - 4k)
        .\]
        Since in practice k is chosen as a small value, i.e. $ k << 1$, we get $ R(x,y) \approx \lambda ^2 $  . Then:
        \begin{itemize}
            \item If $ \lambda \to 0 $ , this means that the derivative of I are close to 0, i.e. the region is flat (homogenous gray levels), and $ R \to 0 $
            \item If $ \lambda > 0 $  then $R > 0$, and we have locally a corner.
        \end{itemize}

        \item If $ \lambda _1 >> \lambda _2 $  (or the reverse) then
        $ R(x,y) \approx \lambda _1 \lambda _2 - k \lambda _1^2 = \lambda _1^2 ( \frac{\lambda _2}{\lambda _1} - k) \approx - k \lambda _1^2$
        If the pixel is an edge, it means that the variations of I are in one direction only, i.e. $ \lambda _1 >> \lambda _2 $ , and we get $ R < 0 $.
    \end{itemize}
\end{proof}





\end{document}